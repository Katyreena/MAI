{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katyreena/MAI/blob/main/CUDA/Labs_2022/ParalellPrograming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MPI+pyTorch\n",
        "###Этап А.  \n",
        "* MasterNode рассылает ComputeNodes нейронки и части датасета для обучения  \n",
        "* ComputeNodes обучают свои модели и информируют MasterNode об этом  \n",
        "\n",
        "###Этап Б. Inference  \n",
        "* К MasterNode передается объект данных для предсказаения.  \n",
        "* MasterNode рассылает его всем ComputeNodes.  \n",
        "* ComputeNodes делают предсказания и отправляют их MasterNode.  \n",
        "* MasterNode на основе всех предсказаний делает голосование и выбирает предсказание.  \n",
        "\n",
        "###Ансамбльный метод:  \n",
        "* Усреднение (если задача регрессии)  \n",
        "* Самый частовыбираемый класс (если задача классификации) или наиболее уверененный  \n",
        "\n",
        "###Отчет: \n",
        "* Что такое MPI\n",
        "* Что такое pyTorch\n",
        "* В чем состоит задача\n",
        "* Из чего состоит датасет\n",
        "* Как выглядит форма голосования\n",
        "* Выводы по сравненнию с использованием 1 процесса"
      ],
      "metadata": {
        "id": "BHpDH2J8uCwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "\n",
        "torch.manual_seed(17)"
      ],
      "metadata": {
        "id": "KeJyZJqaEOFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "082bd40a-f800-45e8-a463-d12cc95b3404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9d99a16dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/train.csv\",dtype = np.float32)\n",
        "test = pd.read_csv(\"/content/test.csv\",dtype = np.float32)\n",
        "\n",
        "train = train[0:100]\n",
        "test = test[0:100]\n",
        "submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "submission = submission[0:100]\n",
        "\n",
        "print(\"Train set shape:\", train.shape)\n",
        "print(\"Test set shape:\", test.shape)"
      ],
      "metadata": {
        "id": "baN0QDP9EOC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86161b67-2fce-406a-9cd2-aadd80168490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (100, 785)\n",
            "Test set shape: (100, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dist = dict(train.label.value_counts())\n",
        "number = label_dist.keys()\n",
        "count = label_dist.values() \n",
        "   \n",
        "fig = plt.figure(figsize = (8, 5)) \n",
        "   \n",
        "plt.bar(number, count, width = 0.5) \n",
        "  \n",
        "plt.xlabel(\"Label\") \n",
        "plt.ylabel(\"No. of samples\") \n",
        "plt.title(\"Distribution of labels\") \n",
        "plt.show() "
      ],
      "metadata": {
        "id": "oIUPR436EOAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "9254ed47-a98e-4056-8a61-06f872140c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train.iloc[0, 1:].values.reshape(28,28))\n",
        "plt.axis(\"off\")\n",
        "plt.title(str(train.iloc[0, 0]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "69iHRSS3EN-f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "9a4c1ddc-8c69-43c5-87d2-42f9f63e3359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy.ndarray\n",
        "labels = train.label.values\n",
        "data = train.iloc[:, 1:].values / 255 # Normalization"
      ],
      "metadata": {
        "id": "0LvFBexdEN7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.Tensor\n",
        "labels = torch.from_numpy(labels).type(torch.LongTensor)\n",
        "data = torch.from_numpy(data).view(data.shape[0], 1, 28, 28)"
      ],
      "metadata": {
        "id": "exd19n6xErnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "gKTE7vkeErkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTensorDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, labels=None, transform=None):      \n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):       \n",
        "        x = self.data[index]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x)\n",
        "        if self.labels is not None:\n",
        "            y = self.labels[index]\n",
        "            return x, y\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def __len__(self):    \n",
        "        return self.data.size(0)"
      ],
      "metadata": {
        "id": "sv1DMKOZErh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomAffine(degrees=20, scale=(1.1, 1.1)),\n",
        "    transforms.RandomCrop((28, 28), padding=2, pad_if_needed=True, fill=0, padding_mode='constant'),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "RY4VGV5OErY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = CustomTensorDataset(train_data[:3], train_labels[:3])\n",
        "sample_aug = CustomTensorDataset(train_data[:3], train_labels[:3], transform=transform)\n",
        "\n",
        "fig, axs = plt.subplots(2, 3)\n",
        "\n",
        "for idx, item in enumerate(zip(sample, sample_aug)):\n",
        "    \n",
        "    im = item[0][0].squeeze().numpy()\n",
        "    im_aug = item[1][0].squeeze().numpy()\n",
        "\n",
        "    axs[0, idx].imshow(im)\n",
        "    axs[0, idx].set_title(\"w/o aug\")\n",
        "    axs[0, idx].axis('off')\n",
        "    \n",
        "    axs[1, idx].imshow(im_aug)\n",
        "    axs[1, idx].set_title(\"aug\")\n",
        "    axs[1, idx].axis('off')"
      ],
      "metadata": {
        "id": "LlgxkQRMErWj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "1d509a28-b3b7-42be-ab78-f0c811a22e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD3CAYAAAC+eIeLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZeklEQVR4nO3de3SU1bnH8d9OIshFbgEJ14AErBxoaS0iFKuVUhWriC0Xpeiy1FOwemzVdrW2x3JWuxQrtee0aq3talFBq6i1gC4VL6daLtaDpHiDclHKRRACmIgQyOQ9f2R833mmTgjJzJ5Lvp+1snx2nved2bDDzp7H992vC4JAAAA/irLdAQBoTZh0AcAjJl0A8IhJFwA8YtIFAI+YdAHAIyZdAPAoLydd59xo59yKbPcD6cW4FibG1crLSVfS+ZKezHYnkHaMa2FiXBPkxKTrnLvCObckob3BObcoob3VOTci4ZQJig+ic26Mc+4V59z78f+OaeR9vu+c2+Scq3HOvemcm5SQm+OcW5DQHuCcC5xzJfH2QOfci/Fzn3XO3Zl4PP4V41qYGNcWCoIg61+STpK0Xw2/BHpL2iJpW0Jun6SieLuXpO2SnKRu8dwMSSWSLom3S1O8z+T46xdJmirpgKRe8dwcSQsSjh0gKZBUEm+vlDRPUhtJYyVVJx7PF+PaWr4Y15Z95cRKNwiCzZJqJI2Q9HlJT0va4Zz7hKQzJb0UBEF9/PAJkp4KGv5mz5e0IQiC+4MgqAuC4EFJ6yRdkOJ9FgVBsCMIgvogCB6StEHSaUfrn3Ouv6SRkm4KguBwEAR/lbS4JX/m1oBxLUyMa8uUZLsDCf4i6SxJFfF4vxoGcHS8/ZEJkh6Ixx/9lk20RVKfj3sD59xlkq5Tw29FSeooqXsT+tZb0t4gCD5M+N5WSf2acG5rx7gWJsa1mXJipRv30SCeEY//ooZBPDMeyzl3XLy9LH7ODknlSa/TXw0fZwznXLmk30q6Wg0fZ7pIel0NH3ukho8u7RNOKUuI35XUzTmXmM+JAcwDjGthYlybK9v1jYSazBA1fGTZGG93krRXDbWY4vj3viDp+YRzStXwG/ZSNazap8bb3T/m9YdKOiTpZEnFkq6QVCfpG/H8eEl71PBD0FnSn2VrRKsk/UwNNaLRkt5XjtSIcvmLcS3ML8a1+V85s9INguAfkj6Q9FK8XS1ps6TlQRDE4oeZS0+CIKiS9GVJ10uqkvQ9SV8OgmDPx7z+m5J+roYC+y5JwyUtT8gvk/SQpLWSVktamvQS09UweFWSfho/trYlf+bWgHEtTIxr87n4b4W84Jx7U9JX4wOS7b48JGldEAQ/znZf8h3jWpgY14+XMyvdo3HOtZF0X7YG0Dk30jk3yDlX5Jw7V9JESY9noy+FhHEtTIxrarl09UKjgiA4LGluFrtQJukxNdSltkmaHQTBmiz2pyAwroWJcU0tr8oLAJDv8qa8AACFgEkXADxqtKY7vmgytYccsax+kTv6UU3DuOaOdI6rxNjmklRjy0oXADxi0gUAj5h0AcAjJl0A8IhJFwA8yps70gAUjuKTK0x7+uIXwnhSh3dNbvKoi0y7bvuOzHXMA1a6AOARky4AeMSkCwAeUdMF4N2GK3qY9rSOuxNadlp680d9TXvIbGq6AIAmYtIFAI8oLwDwbs6kh5t8bIcthTVNsdIFAI+YdAHAIyZdAPCosIolAHLWe1eNCeNz2t+WlG0XRvWy+7B32RjLZLe8Y6ULAB4x6QKAR5QXAHjR7eJtYdy1qF3K44b+ZaZpn/TIyxnrUzaw0gUAj5h0AcAjJl0A8Cina7olfXqH8TuXDTC50yeuDeMXXxxuchU3rQnj+kOHMtM5ZFzy0wU2fD3amWr82WtM7le9V9hzXbSemLJ5nMm98eTJYdz3Znse/EgcH0mKBfVhXFdb7Ls7XrHSBQCPmHQBwKOcLi/suKtTGK/97B0mN2vbGWG8eMrPTe7+8aeHceUU+xE1tmFzOruIFnJt25r21utODePFs35mcgNK2odxnexdStfsOMO0v9Tl9TBeOPAZkyv61rIwHvv2VSbX6cFVTek2mqD4lMGmPX/IH8I4FrQ3udqgLoxPuj+z/co2VroA4BGTLgB4xKQLAB7ldE23c7vocq9Tb73a5Hr+amUY31A+zeSGPrY1jLvdu9fkdo8Rsqy4U1Sr33qvfejg2tOi2v2+emdyI34R/QyUvXzQ5IpespeQ/VpRLf/G/7SD/syVUa34sVvnmdzF7oYw7vQA9d2WGLLgbdM+sbh9iiOlsa/OCOMez6/OWJ9yAStdAPCISRcAPMrp8kK7G44P4/ZHdptcLIg2Oq57558m9/rXh4bx7xffY3LTvnydaR+/9G8t7icaV9Shg2m3WRLtMFVZscDkzl9/QRi76zqbXO/K5t091u8n9rxHpg0L42u62EsIY9OrosYDzXq71q0ouptsRrfkuwTbhHHiHWiS5J7oltl+5RBWugDgEZMuAHjEpAsAHuV0Tbd+7brmnVf5ZhiPecLWcDvO/MC0ey9t1lvgGKy/2e4Ct6HirjCetHGCyRVdVBPGsertGenP3Y+eF8bXzLzT5Kr2dgzjrhl598JWNfO0MB7R5hWTS6zj/uOI3f2v+29WqrVgpQsAHjHpAoBHOV1eSIdulXZD5Buvt/WEe3SSz+60GsWl0SVA8y+42+ReO3wkjI9cay8Vqq/emdmOSer6VnS5YXW9/Zg76K765MORARNXzTLtgVqb4sjCw0oXADxi0gUAj5h0AcCjgq/p9nxso/3G9dnpR2uz6TvRwx8/1/ZZk6t4Jnpaw5BK/ztK7TwzqtuuqLU15eKa2jCmups5dVXtjn5QE5QMLDft3WdGD7Pd81k7goMXRDvTuTXrTS6orZUvrHQBwCMmXQDwKKfKC8U9eph2bPfuFEc23a5JFUnfebnFr4mjO9I19YfzE7p+GMabbhttcn2fjx5QeLCH/fEsffyNMI4NHWBye4fancz2Do8uCzt7zGsmN7/X7WGcvLH2d6ZH96EN/MHHdh9pMGfco6b9x6Fnh3Fs3SaTe2/WKNNuf2F0WeGPK5aY3Lh2jZQJJkXhF66yl6y1+7O/3QZZ6QKAR0y6AOARky4AeOSChCcwJBtfNDl1MgNOeKm7aX+tLHow4PdWX2xyFT9K2I1qo30AXqLND4ww7eKSmGmXT7H1vly1rH6RO/pRTeNjXEvK+4Xx5cteNLmvdNjXrNfcHotqwasO9TG51QcGmvaf1n8yjMu61pjcC8OieuL9NWUm9/DnoqdKxKrsQ00zIZ3jKvn/N5vMtW0bxnPX2XEf3ua4lOe9lzC2NYH9KxlUkp7LyxIl73J27aWzw9it+Hta3iPV2LLSBQCPmHQBwCMmXQDwKKeu053S0+40v/5QrzAeUmav2b3t2agu16PYlrEu2zg5jFdW2CcDjHrE3gdc3PPEJvUt+OCAadcfiNpFxx9vcq5zp+i4pLpgUFen1qBuy9Ywnj/qMyZ3+4ToFuH9Q1L/3i+2ZTf1fSHhqR+rGt8KMHGrwPrn+qU87o55XzHt0qrW8wSDTEi8nXbWW9NNbvmnHk55XuL10k37F9kyZXbHVx3uEj2puK0yi5UuAHjEpAsAHuVUeeGO70417a/NjZ7ysG613U1owrpvh/Ej59xhckuGROfNrx5kcvdNvMu0T5+Suj/FLvqd9PiBjia3pCq6FG1kJ3vJ2pWdo4/WN75nP1rvqbWvk2hzTWkY71vSJ+Vx+Sa2z14i1nlhdClg5wy9Z/Wlp4fxcyf/0uS2xw6HcenvKCdkSpcL3zHtyc+fE8aLBj3tuTfWog/s9gBtn3wlxZHpx0oXADxi0gUAj5h0AcCjnKrpJm+vdm+bC8K4zdQPTG5U3y1h/MO3J5ncjqVR/bf3L+1rFnf/lGnH+thbj5tqz6ejy8LWlAw3ucdfqW7WayZeqlKm95v1Gq2Ws3dcHnf5rjBu6+yP+RdXfCOMW9NTaH1Lvjzy/cPpv523Mcm3eM996KthPHBe8u3/NfKFlS4AeMSkCwAe5VR5IVnHRS8nxDa3w7TsR4Ne2h7GyVsu1e3cZb+R3G6i0kaep5jVbZ5aqZop9ukCLw2LLg3cVHfQ5AZ/N7pLsHXcH1i4FtbY+9cenPalMC7aWWVy5TtXhHE2HzrKShcAPGLSBQCPmHQBwKOcrukCTfXuuFjK3MQ/fNe0+29dkeJI5Js5qyaa9uDK6H+2ZLNu2xhWugDgEZMuAHhEeQF5qWSg3XXu+XN+kXREtCl2v2UfCtm387m+YfzPwXZM+pe0Tz48dPmWs037ndujTfBPWbXN5PLhEkBWugDgEZMuAHjEpAsAHlHTRV7adqF9skZyTXDk6kvCuMfySi99QuP63hJdqjfrlrHHcOZ+0+qgaHuAfKjhJmOlCwAeMekCgEeUF5CXrp/9cKP52pWljeaBbGGlCwAeMekCgEdMugDgETVd5I2iEUPDePoJr5rcsoP2oYfl96wL49T7jwH+sdIFAI+YdAHAI8oLyBubpnYO42Jn1wtVsY724BJ+tJGbWOkCgEdMugDgEZMuAHhE4Qt5o9Om1Llb3jjXtPvseiPDvQGah5UuAHjEpAsAHlFeQN4o/d3KMD7ndyNMro8oJyA/sNIFAI+YdAHAIyZdAPDIBUGQ7T4AQKvBShcAPGLSBQCPmHQBwCMmXQDwiEkXADxi0gUAj5h0AcCjvJ50nXPfd85tcs7VOOfedM5Nin9/jnNuQcJxA5xzgXOuJN4e6Jx7MX7es865OxOPR3YxroWJcW2Q15OupE2SzpDUWdJ/SVrgnOvVhPMekPQ3SaWS5kiakakOolkY18LEuCrPdxkLgmBRQvMh59wPJJ3W2DnOuf6SRkoaFwTBYUl/dc4tzmA3cYwY18LEuDbI65Wuc+4y51ylc26/c26/pGGSuh/ltN6S9gZB8GHC97ZmrJM4ZoxrYWJcG+TtpOucK5f0W0lXSyoNgqCLpNclOUkHJLVPOLwsIX5XUjfnXGK+X4a7iyZiXAsT4xrJ20lXUgdJgaTdkuScu0INvzklqVLS551z/Z1znSX94KOTgiDYIun/JM1xzrVxzo2WdIHXnqMxjGthYlzj8nbSDYLgTUk/l7RS0i5JwyUtj+eWSXpI0lpJqyUtTTp9uqTRkqok/TR+bK2XjqNRjGthYlwjbO0oyTn3kKR1QRD8ONt9QfowroUp38c1b1e6LeGcG+mcG+ScK3LOnStpoqTHs90vtAzjWpgKbVzz+pKxFiiT9JgarvvbJml2EARrstslpAHjWpgKalwpLwCAR62yvAAA2dJoeWF80WSWwTliWf0il67XYlxzRzrHVcqfsd08d7Rpr5txZ5PPrVg8K4yHzP5b2vqUbqnGlpUuAHjEpAsAHjHpAoBHrfWSMQBZNGfSw80+t8OW/J62WOkCgEdMugDgUX6v0wHkjfeuGhPG57S/zeT21Udx16J2JlcvexVcl42x9HfOI1a6AOARky4AeMSkCwAe5U1Nt6RP75S5uu07PPYEQHN0u3hbGCfXbRsz9C8zTfukR15OW5+ygZUuAHjEpAsAHuVNeWHHXZ1M+/CqbmF8+sTqlOe9+OJw0664ye59XH/oUBp6B+BYFLvU671YUG/adbXFme6OV6x0AcAjJl0A8IhJFwA8ypuabud2tvb63NV3hPGsbWeY3HU9l4Vxz/G23rvmpvYZ6B2AY/Fu3QemfWJx9O+yNqgzuZPu99Ilb1jpAoBHTLoA4FHelBeSnXrr1WHc81crTe6G8mlhPPSxrSbn+iXd2bZhc/o7h6zbdmO0o1Xfm1dksSetV/Epg017/pA/NOt1Sp5fnY7u5AxWugDgEZMuAHjEpAsAHuV0Tbfok58I43Y32Fz7I7vDOBbYneXr3vlnQsuZXLd795r27jFCDtl86+gwHn+2vWX7V72j2mzybaRTNo8z7W1PRnH1JaebXKcHV7W0m2iCIQveNu1bd58Vxj8v+1vK88a+OsO0e2h9WvuVbax0AcAjJl0A8Cinywv1a9e1+DVe//oppv37xfeY9rQvXxfGxy9N/ZEH6VN8ckWTjvtF75dM+5od0Z2HX+ryusktHPiMaRd9K7orcewNV5lc9aW23JCo0wOUHlqkKNoRbEa31JfqFbs2pp24s5h7olvy4QWFlS4AeMSkCwAeMekCgEc5XdNNh/rKN017zBPXmXbHmdFuR72XeulSq+Datk2Z23LxiWG8eNbPTG5ASbTb1LnT/t3kil6KLiH7tWxd+Mb/tNf+PXNl9LqLbp1ncr0SdrQaXTnVdu6BlN1GE1TNPC2MR7R5JeVxyU+H+MeRaBfB7r9ZmXx4QWGlCwAeMekCgEcFX17Y883Rpj1v3MKUx96jkzLdnVajKKG8sPXevia39rRoA/p99faOwRG/iHaPK9PBJr9fv5/Yy5Nm/mRsGJ/3xn6Tu6ZLtLNc1d6OJte1ye+Ioxk151um/fKcO1MeO3HVrDAeqLUZ61MuYKULAB4x6QKAR0y6AOBR1mu6xT16hHFs9+5Gjmyeno9ttN+43jbvGUIdN9MqT1tg2uevvyCM3XWdTa53Zfqf8nD3o+eZ9jUzo9rioLvqkw9HFtRVtUvL65QMLA/j3Wfap8Ts+WzqsR68IPr/B26N3dUsqK1NS98+wkoXADxi0gUAj7JeXmj/WLQB+dfKbCnge6svDuOKH9WYXGyj3SA5lV2Tkne0evnYOogmKerQwbTbLEn9cbHoomgsY9XbM9anj3R9y25yX11/KMWRaKnS30Z3k1VdObqRI6054x4N4z8OPdvkYus2mfZ7s0aFcfsLd5rcjyuWhPG4dsdQFpgUhV+4apZJtftzencfZKULAB4x6QKAR0y6AOBR1mu6U3pGOxGtP9TL5IaURZeQ3fbsoyb37QFNe6Jk9Vn2VtIfVk407XK91qTXQePW3zzctDdU3BXGkzZOMLlYta3DZdrOM+2lQitqoycTFNck1f2GRQ9DrX+95U8uac263/eqab9245EwHt7mOJObfsJ7YTz+qd+bXE1gbxUfVJJ697J0+M3//LdpX7t7dhi7FX9v8euz0gUAj5h0AcCjrJcX7vhutIn01+baXcTXrY7uLtEAe97CrcvD+LKNk03uvopFCa3lJjd2pb0cBM1XXBp9TJ9/wd0m99rh6KPkkWvtgwaLRkTt5E3m06X/y9ElbPN73Z7yuKVP213LT7kv2hlr4A/S36/WJPlOrllvTQ/j5Z96OOV5JyZsMi9JJ6Y4LlPKim37cJfoIZqpt+ZvOla6AOARky4AeMSkCwAeZb2mG2sTXQ5y700XmFybqdFDIyc89W2Te+Sc6OkDS4bYWvD86kFhfPNTF5ncyXM3m7Z6Nq1iFNv13tEPamU2fefkMP5c22dNruKZq6LGtfa8IVesDuPa80aa3MEe0Y9k6eNvmFxs6IAw3jvU3na8d7i91ffg/l1hPHX/DJN7YVh0+eH9NWW23/OiHaZiQjp1ufCdMJ78/Dkmt2jQ0557k9qiD+zWAW2fTO8laqx0AcAjJl0A8IhJFwA8ynpNt+Oi1Fst7ps6LIzPGvGWyf3w7Wgvth1Ly02u9y+jrdju+8ddJnf6lNR9KXapfwedN/hzpl1/4EAYFx1/vMm5zp3CuJBrwUe6RrfXDn58tsltvOjXYfzpV6ab3Kbboi3/+j5fZ3Irbome6rD9px+a3KpDfcJ49YGBjfbtT+s/GcblPfalPO6OeV8x7dKqlSmORCFJruXPfeirYTxwXvLWADVKJ1a6AOARky4AeJT18kJj+n319TDe8S/ZaMnfS0lPHyiJ/lg3j7EPJYz16d7k95/1xz+Hce/nXFK2YxiN7GSfYnFl561hfH75aSYX1NmP0/ls8Lei0lBJeT+Te3R81zBeM3KhPTHxKrFLU7/+lVOust9YtbbJfRuo6Ng/bbM7/2+PHQ7j0t9RTvAl8Wf//cPpeRBlYxbW2MtBH5z2pTAu2lllcuU7oweiZvpRpax0AcAjJl0A8IhJFwA8yumabnMl1o7qdu6yyeR2Anfqv5n23dOip0zs+XQnk6tP+Jvb/oq9ZO3KxfeH8adesTXcPbUdlcrmmtIwbjN+S8rj8sH8UZ8J49snnGxy+4ek/l1fnPCg3r6rVqQ87miqLz09oWVrul9cEdWKE2u/KCxzVtmnxAyujG4/z3TdtjGsdAHAIyZdAPCoIMsLzRWsfiNlrnR1ypSCpPb5F8742OOOam60q9qu/2jagzdzRd2WrSlznReusu1MdMDZS/qOuzwqI7V1/Jgjd7DSBQCPmHQBwCMmXQDwiGJXBjRWG25M2+9Hl6yV6f10dadVqJkyyrRfGhbtLrep7qDJLR0d7YB2jezucfBj53N9Tfufg6Md5fqXtE8+3Lh8y9kpc+/cHl2eeMqqbSaXKzfgs9IFAI+YdAHAI8oLOaS5ZQlI746zj5GseOKbYbzx/N+Y3LDfXh3G/dX8u97QfH1vsX/vs24Zewxn70+Z6aBo57tcKSckY6ULAB4x6QKAR0y6AOARNV0UhKG32AeA3vG/iU+rsJcg9VtmH3gJ+MRKFwA8YtIFAI8oL6AgbLuwj2kn3tU0cvUlJtdjeaWXPgEfh5UuAHjEpAsAHjHpAoBH1HRR8GpXlh79IMATVroA4BGTLgB4RHkBBeH62Q+nzJXfs860YymOA3xgpQsAHjHpAoBHTLoA4BE1XeSlohFDTXv6Ca+a9rKD7aLcir+b3MLPnxrGsV12dzIg01jpAoBHTLoA4BHlBeSlTVM7m3axs+uHc9vXhvHCmo4mR0kB2cRKFwA8YtIFAI+YdAHAIxcEQbb7AACtBitdAPCISRcAPGLSBQCPmHQBwCMmXQDwiEkXADz6fy1sgYTwEyzvAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create training and validation sets\n",
        "trainset = ConcatDataset([\n",
        "    CustomTensorDataset(train_data, train_labels),\n",
        "    CustomTensorDataset(train_data, train_labels, transform=transform)\n",
        "])\n",
        "valset = CustomTensorDataset(val_data, val_labels)"
      ],
      "metadata": {
        "id": "idq_OPXsErUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create dataloaders to make use of batching and shuffling\n",
        "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(valset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "8We3hu9tErRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1m_1KSz9E4kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet_18(nn.Module):\n",
        "    \n",
        "    def __init__(self, image_channels, num_classes):\n",
        "        \n",
        "        super(ResNet_18, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        #resnet layers\n",
        "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
        "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
        "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
        "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def __make_layer(self, in_channels, out_channels, stride):\n",
        "        \n",
        "        identity_downsample = None\n",
        "        if stride != 1:\n",
        "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
        "            \n",
        "        return nn.Sequential(\n",
        "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
        "            Block(out_channels, out_channels)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x \n",
        "    \n",
        "    def identity_downsample(self, in_channels, out_channels):\n",
        "        \n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )"
      ],
      "metadata": {
        "id": "PRl-uGa7E4iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet_18(1, 10)"
      ],
      "metadata": {
        "id": "l6ZrYcGwE4fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count trainable parameters of the model\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ],
      "metadata": {
        "id": "bNeraZNEE4dW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f29f55c-ebdc-4227-856b-b8cc37c7f172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12556426"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define everything we need for training\n",
        "epochs = 1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
      ],
      "metadata": {
        "id": "sf-m8DcOFF4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=50, is_inception=False):\n",
        "    \n",
        "    since = time.time()\n",
        "    val_acc_history = []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]: # Iterate over data\n",
        "                \n",
        "                inputs = transforms.functional.resize(inputs, (112, 112))\n",
        "\n",
        "\n",
        "\n",
        "                optimizer.zero_grad() # Zero the parameter gradients\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n",
        "                    \n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train': # Backward + optimize only if in training phase\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            if phase == 'val': # Adjust learning rate based on val loss\n",
        "                lr_scheduler.step(epoch_loss)\n",
        "                \n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "metadata": {
        "id": "y_rzj7S2FF1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, _ = train_model(model, {\"train\": train_loader, \"val\": val_loader}, criterion, optimizer, epochs)"
      ],
      "metadata": {
        "id": "5wTQnxVUFFzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be0e891-c8d2-4f98-c3de-7b54b55bdc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/0\n",
            "----------\n",
            "train Loss: 2.1164 Acc: 0.2562\n",
            "val Loss: 2.2762 Acc: 0.1500\n",
            "\n",
            "Training complete in 0m 13s\n",
            "Best val Acc: 0.150000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare test set for the model\n",
        "test = test.values / 255\n",
        "test = torch.from_numpy(test).view(test.shape[0], 1, 28, 28)"
      ],
      "metadata": {
        "id": "ZA9Q3LZaFFw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a dataloader with the test set\n",
        "testset = CustomTensorDataset(test, None)\n",
        "test_loader = DataLoader(testset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "qOiVVAjUFFuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turn on the evaluation mode and make predictions batch by batch (otherwise it lack gpu memory)\n",
        "#to use predictions for the submission we first need to transfer to the cpu\n",
        "model.eval()\n",
        "labels = []\n",
        "for inputs in test_loader:\n",
        "    inputs = transforms.functional.resize(inputs, (112, 112))\n",
        "    outputs = model(inputs)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    predictions = predictions.to(\"cpu\")\n",
        "    labels.extend(predictions.numpy())\n",
        "    break"
      ],
      "metadata": {
        "id": "iDCxgktwFRm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mPA4bC9L2tX",
        "outputId": "693cc84b-80bb-4846-e751-2648de21f54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mpi"
      ],
      "metadata": {
        "id": "ksdRe6dEMLNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rzFXHSQMRkX",
        "outputId": "657f8685-b918-49c8-fbaf-b1b67226ff5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 27.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp38-cp38-linux_x86_64.whl size=4438526 sha256=20c6627e5b71bd9f72eed8e7fff3dd9e2352506048b59ad879d127d6515e64a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/35/48/0b9a7076995eea5ea64a7e4bc3f0f342f453080795276264e7\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "import time\n",
        "import math\n",
        "from scipy import random\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.rank\n",
        "size = comm.size\n",
        "data = None \n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomAffine(degrees=20, scale=(1.1, 1.1)),\n",
        "    transforms.RandomCrop((28, 28), padding=2, pad_if_needed=True, fill=0, padding_mode='constant'),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "if rank == 0:\n",
        "  train = pd.read_csv(\"/content/train.csv\",dtype = np.float32)\n",
        "  data = [train[x*20: x*20 + 20] for x in range(size)]\n",
        "  print(\"Рассылаем всем вычислительным узлам свою часть датасета\")\n",
        "\n",
        "interval = comm.scatter(data, root=0)\n",
        "\n",
        "data = None\n",
        "if rank != 0:\n",
        "  train = interval\n",
        "  labels = train.label.values\n",
        "  data = train.iloc[:, 1:].values / 255 # Normalization\n",
        "  labels = torch.from_numpy(labels).type(torch.LongTensor)\n",
        "  data = torch.from_numpy(data).view(data.shape[0], 1, 28, 28)\n",
        "  train_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size = 0.2, random_state = 42)\n",
        "  \n",
        "  class CustomTensorDataset(Dataset):\n",
        "    def __init__(self, data, labels=None, transform=None):      \n",
        "      self.data = data\n",
        "      self.labels = labels\n",
        "      self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):       \n",
        "      x = self.data[index]\n",
        "       \n",
        "      if self.transform is not None:\n",
        "        x = self.transform(x)\n",
        "      if self.labels is not None:\n",
        "        y = self.labels[index]\n",
        "        return x, y\n",
        "      else:\n",
        "        return x\n",
        "\n",
        "    def __len__(self):    \n",
        "      return self.data.size(0)\n",
        "  trainset = ConcatDataset([\n",
        "    CustomTensorDataset(train_data, train_labels),\n",
        "    CustomTensorDataset(train_data, train_labels, transform=transform)\n",
        "  ])\n",
        "  valset = CustomTensorDataset(val_data, val_labels)\n",
        "  train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "  val_loader = DataLoader(valset, batch_size=32, shuffle=False)\n",
        "  \n",
        "  class Block(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "  \n",
        "  class ResNet_18(nn.Module):\n",
        "    \n",
        "    def __init__(self, image_channels, num_classes):\n",
        "        \n",
        "        super(ResNet_18, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        #resnet layers\n",
        "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
        "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
        "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
        "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def __make_layer(self, in_channels, out_channels, stride):\n",
        "        \n",
        "        identity_downsample = None\n",
        "        if stride != 1:\n",
        "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
        "            \n",
        "        return nn.Sequential(\n",
        "            Block(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
        "            Block(out_channels, out_channels)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x \n",
        "    \n",
        "    def identity_downsample(self, in_channels, out_channels):\n",
        "        \n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "  model = ResNet_18(1, 10)\n",
        "  epochs = 1\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "  lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
        "  \n",
        "  def train_model(model, dataloaders, criterion, optimizer, num_epochs=50, is_inception=False):\n",
        "    val_acc_history = []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]: # Iterate over data\n",
        "                \n",
        "                inputs = transforms.functional.resize(inputs, (112, 112))\n",
        "\n",
        "\n",
        "\n",
        "                optimizer.zero_grad() # Zero the parameter gradients\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n",
        "                    \n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train': # Backward + optimize only if in training phase\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            if phase == 'val': # Adjust learning rate based on val loss\n",
        "                lr_scheduler.step(epoch_loss)\n",
        "                \n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n",
        "  \n",
        "  model, _ = train_model(model, {\"train\": train_loader, \"val\": val_loader}, criterion, optimizer, epochs)\n",
        "  \n",
        "  data = \"Узел №\" +str(rank) + \" обучился\"\n",
        "\n",
        "data = comm.gather(data,root=0)\n",
        "\n",
        "if rank == 0:\n",
        "  print (\"Этап 'А' выполнен! Узлы обучили модели:\", data)\n",
        "  print(\"Inference. Рассылаем ComputeNodes объект данных для предсказания\")\n",
        "  test = pd.read_csv(\"/content/test.csv\",dtype = np.float32)\n",
        "  data = test[0:100]\n",
        "\n",
        "data = comm.bcast(data)\n",
        "\n",
        "if rank != 0:\n",
        "  test = data\n",
        "  test = test.values / 255\n",
        "  test = torch.from_numpy(test).view(test.shape[0], 1, 28, 28)\n",
        "  testset = CustomTensorDataset(test, None)\n",
        "  test_loader = DataLoader(testset, batch_size=1, shuffle=False)\n",
        "  model.eval()\n",
        "  labels = []\n",
        "  for inputs in test_loader:\n",
        "    inputs = transforms.functional.resize(inputs, (112, 112))\n",
        "    outputs = model(inputs)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    predictions = predictions.to(\"cpu\")\n",
        "    labels.extend(predictions.numpy())\n",
        "    break\n",
        "  data = labels[0]\n",
        "\n",
        "\n",
        "data = comm.gather(data,root=0)\n",
        "\n",
        "if rank == 0:\n",
        "  print (\"Этап 'Б' выполнен! Предсказания получены\")\n",
        "  tmp = dict()\n",
        "  for i in data[1:]:\n",
        "    if i in tmp:\n",
        "      tmp[i] += 1\n",
        "    else:\n",
        "      tmp[i] = 1\n",
        "  max_val = max(tmp.values())\n",
        "  final_dict = {k:v for k, v in tmp.items() if v == max_val}\n",
        "  final = list(final_dict.keys())\n",
        "\n",
        "  r = np.random.randint(0, len(final))\n",
        "\n",
        "  print(\"Результат голосования: \", final[r])\n"
      ],
      "metadata": {
        "id": "MjLCctnWMMV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun -np 4 --allow-run-as-root python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my0unP9hTApS",
        "outputId": "8f123fde-2942-405f-88e1-2a96482d8451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Рассылаем всем вычислительным узлам свою часть датасета\n",
            "\n",
            "\n",
            "\n",
            "Этап 'А' выполнен! Узлы обучили модели: [None, 'Узел №1 обучился', 'Узел №2 обучился', 'Узел №3 обучился']\n",
            "Inference. Рассылаем ComputeNodes объект данных для предсказания\n",
            "Этап 'Б' выполнен! Предсказания получены\n",
            "Результат голосования:  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3o834Fl1rejr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}